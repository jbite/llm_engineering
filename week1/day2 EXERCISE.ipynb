{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d15d8294-3328-4e07-ad16-8a03e9bbfdb9",
   "metadata": {},
   "source": [
    "# Welcome to your first assignment!\n",
    "\n",
    "Instructions are below. Please give this a try, and look in the solutions folder if you get stuck (or feel free to ask me!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada885d9-4d42-4d9b-97f0-74fbbbfe93a9",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../resources.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#f71;\">Just before we get to the assignment --</h2>\n",
    "            <span style=\"color:#f71;\">I thought I'd take a second to point you at this page of useful resources for the course. This includes links to all the slides.<br/>\n",
    "            <a href=\"https://edwarddonner.com/2024/11/13/llm-engineering-resources/\">https://edwarddonner.com/2024/11/13/llm-engineering-resources/</a><br/>\n",
    "            Please keep this bookmarked, and I'll continue to add more useful links there over time.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9fa1fc-eac5-4d1d-9be4-541b3f2b3458",
   "metadata": {},
   "source": [
    "# HOMEWORK EXERCISE ASSIGNMENT\n",
    "\n",
    "Upgrade the day 1 project to summarize a webpage to use an Open Source model running locally via Ollama rather than OpenAI\n",
    "\n",
    "You'll be able to use this technique for all subsequent projects if you'd prefer not to use paid APIs.\n",
    "\n",
    "**Benefits:**\n",
    "1. No API charges - open-source\n",
    "2. Data doesn't leave your box\n",
    "\n",
    "**Disadvantages:**\n",
    "1. Significantly less power than Frontier Model\n",
    "\n",
    "## Recap on installation of Ollama\n",
    "\n",
    "Simply visit [ollama.com](https://ollama.com) and install!\n",
    "\n",
    "Once complete, the ollama server should already be running locally.  \n",
    "If you visit:  \n",
    "[http://localhost:11434/](http://localhost:11434/)\n",
    "\n",
    "You should see the message `Ollama is running`.  \n",
    "\n",
    "If not, bring up a new Terminal (Mac) or Powershell (Windows) and enter `ollama serve`  \n",
    "And in another Terminal (Mac) or Powershell (Windows), enter `ollama pull llama3.2`  \n",
    "Then try [http://localhost:11434/](http://localhost:11434/) again.\n",
    "\n",
    "If Ollama is slow on your machine, try using `llama3.2:1b` as an alternative. Run `ollama pull llama3.2:1b` from a Terminal or Powershell, and change the code below from `MODEL = \"llama3.2\"` to `MODEL = \"llama3.2:1b\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e2a9393-7767-488e-a8bf-27c12dca35bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29ddd15d-a3c5-4f4e-a678-873f56162724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2:1b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dac0a679-599c-441f-9bf2-ddc73d35b940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a messages list using the same format that we used for OpenAI\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Describe some of the business applications of Generative AI\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bb9c624-14f0-4945-a719-8ddb64f66f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": False\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8deae3e-0f63-4ecd-b5e4-0c7be271e185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'llama3.2:1b',\n",
       " 'messages': [{'role': 'user',\n",
       "   'content': 'Describe some of the business applications of Generative AI'}],\n",
       " 'stream': False}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "479ff514-e8bd-4985-a572-2ea28bb4fa40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[?25lpulling manifest ��� \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ��� \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ��� \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ��� \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ��� \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ��� \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ��� \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling 74701a8c35f6... 100% ������������������������������������������������������ 1.3 GB                         \n",
      "pulling 966de95ca8a6... 100% ������������������������������������������������������ 1.4 KB                         \n",
      "pulling fcc5a6bec9da... 100% ������������������������������������������������������ 7.7 KB                         \n",
      "pulling a70ff7e570d9... 100% ������������������������������������������������������ 6.0 KB                         \n",
      "pulling 4f659a1e86d7... 100% ������������������������������������������������������  485 B                         \n",
      "verifying sha256 digest \n",
      "writing manifest \n",
      "success \u001b[?25h\n"
     ]
    }
   ],
   "source": [
    "# Let's just make sure the model is loaded\n",
    "\n",
    "!ollama pull llama3.2:1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42b9f644-522d-4e05-a691-56e7658c0ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has a wide range of business applications across various industries. Here are some examples:\n",
      "\n",
      "1. **Product Design and Development**: Generative AI can help companies create innovative products by generating multiple design options based on customer feedback, market trends, or design guidelines. This enables businesses to iterate quickly and improve their designs.\n",
      "2. **Content Creation**: AI-powered content generation tools, such as language models and chatbots, can assist content creators in writing, editing, and publishing high-quality content. This reduces the workload of human writers and allows companies to produce more content faster.\n",
      "3. **Marketing and Advertising**: Generative AI can generate personalized ads, product descriptions, and social media posts based on customer data and preferences. This helps businesses target their audience more effectively and increase engagement.\n",
      "4. **Customer Service**: Chatbots powered by generative AI can provide 24/7 customer support, answering frequently asked questions, routing complex issues to human agents, and even learning from customer interactions to improve future responses.\n",
      "5. **Financial Services**: Generative AI can help financial institutions create personalized investment advice, predict market trends, and identify potential risks. It can also assist in risk management and compliance by generating reports and identifying suspicious activity.\n",
      "6. **Healthcare**: AI-powered tools can analyze medical images, generate 3D models of patient anatomy, and even assist in medical diagnosis. This enables healthcare professionals to make more accurate diagnoses and develop personalized treatment plans.\n",
      "7. **Cybersecurity**: Generative AI can help security experts create customized threat detection systems, identify vulnerabilities, and predict potential attacks. This reduces the time and effort required to respond to cyber threats.\n",
      "8. **Supply Chain Management**: AI-powered tools can analyze demand forecasts, optimize inventory levels, and predict supply chain disruptions. This helps companies improve their logistics and reduce costs.\n",
      "9. **Education and Training**: Generative AI can create personalized learning materials, adaptive assessments, and even simulate real-world scenarios for students. This enhances the effectiveness of education and training programs.\n",
      "10. **Predictive Analytics**: AI-powered predictive models can analyze customer behavior, market trends, and other data to forecast sales, revenue, or other business outcomes. This enables businesses to make informed decisions and optimize their operations.\n",
      "\n",
      "These are just a few examples of the many business applications of Generative AI. As the technology continues to evolve, we can expect to see even more innovative uses across various industries.\n"
     ]
    }
   ],
   "source": [
    "# If this doesn't work for any reason, try the 2 versions in the following cells\n",
    "# And double check the instructions in the 'Recap on installation of Ollama' at the top of this lab\n",
    "# And if none of that works - contact me!\n",
    "\n",
    "response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)\n",
    "print(response.json()['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a021f13-d6a1-4b96-8e18-4eae49d876fe",
   "metadata": {},
   "source": [
    "# Introducing the ollama package\n",
    "\n",
    "And now we'll do the same thing, but using the elegant ollama python package instead of a direct HTTP call.\n",
    "\n",
    "Under the hood, it's making the same call as above to the ollama server running at localhost:11434"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7745b9c4-57dc-4867-9180-61fa5db55eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has a wide range of business applications across various industries. Here are some examples:\n",
      "\n",
      "1. **Content Generation**: Generative AI can help automate content creation for companies, such as blog posts, social media content, and even entire websites. This can save time and resources, allowing businesses to focus on higher-level strategic tasks.\n",
      "\n",
      "2. **Virtual Product Demos**: Generative AI can create realistic virtual product demos that showcase products in a more engaging way than traditional screenshots or videos. This can be especially useful for e-commerce companies looking to showcase their products in the digital world.\n",
      "\n",
      "3. **Customer Service Chatbots**: Generative AI-powered chatbots can help businesses provide personalized customer support by generating responses to frequently asked questions and routing complex queries to human agents when needed.\n",
      "\n",
      "4. **Image Editing and Design**: Generative AI can be used to generate new images, logos, or designs based on existing ones. This can help designers save time and reduce the need for manual creativity.\n",
      "\n",
      "5. **Predictive Maintenance**: Generative AI can analyze sensor data from machines and predict maintenance needs, reducing downtime and increasing overall efficiency.\n",
      "\n",
      "6. **Sales Pitch Generation**: Generative AI can create sales pitches that are tailored to individual customers based on their preferences, interests, and company history.\n",
      "\n",
      "7. **Personalized Marketing**: Generative AI can help businesses personalize marketing campaigns by generating customized content, such as product recommendations or special offers, for each customer based on their browsing and purchasing history.\n",
      "\n",
      "8. **Product Recommendation Systems**: Generative AI-powered recommendation systems can suggest products to customers based on their purchase history, interests, and preferences, helping to increase sales and customer engagement.\n",
      "\n",
      "9. **Research Assistance**: Generative AI can assist researchers by analyzing large datasets, identifying patterns, and providing insights that human researchers might miss.\n",
      "\n",
      "10. **Quality Control and Inspection**: Generative AI can be used to analyze images or videos of products in real-time, detecting defects or anomalies that would require manual inspection.\n",
      "\n",
      "11. **Automated Data Labeling**: Generative AI can help automate the process of data labeling by assigning labels to large datasets automatically, freeing up human researchers to focus on more complex tasks.\n",
      "\n",
      "12. **Speech Recognition**: Generative AI-powered speech recognition technology can transcribe audio recordings into text with high accuracy and speed, reducing manual typing time and increasing productivity in fields like healthcare and finance.\n",
      "\n",
      "13. **Video Annotation**: Generative AI can be used to annotate videos by labeling key events or objects automatically, helping video analysts identify patterns and trends that would require human review.\n",
      "\n",
      "14. **Predictive Analytics**: Generative AI can help businesses predict customer behavior, such as churn rates or purchase likelihood, based on historical data and patterns, allowing for proactive strategies to retain customers.\n",
      "\n",
      "15. **Cybersecurity Threat Detection**: Generative AI-powered systems can analyze network traffic and detect potential threats in real-time, helping organizations stay ahead of cyber attacks and protect their assets.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "response = ollama.chat(model=MODEL, messages=messages)\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4704e10-f5fb-4c15-a935-f046c06fb13d",
   "metadata": {},
   "source": [
    "## Alternative approach - using OpenAI python library to connect to Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23057e00-b6fc-4678-93a9-6b31cb704bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There's actually an alternative approach that some people might prefer\n",
    "# You can use the OpenAI client python library to call Ollama:\n",
    "\n",
    "from openai import OpenAI\n",
    "ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1622d9bb-5c68-4d4e-9ca4-b492c751f898",
   "metadata": {},
   "source": [
    "# NOW the exercise for you\n",
    "\n",
    "Take the code from day1 and incorporate it here, to build a website summarizer that uses Llama 3.2 running locally instead of OpenAI; use either of the above approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "402d5686-4e76-4110-b65a-b3906c35c0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d49de72-9863-46e0-9314-3c868da4fc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2:1b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba274eb8-4c0c-41bf-b4c7-d05a7e4f2d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "class Website:\n",
    "\n",
    "    def __init__(self, url):\n",
    "        \"\"\"\n",
    "        Create this Website object from the given url using the BeautifulSoup library\n",
    "        \"\"\"\n",
    "        self.url = url\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "            irrelevant.decompose()\n",
    "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6926cba7-13b6-4296-a045-9ba854fb4c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Home - Edward Donner\n",
      "<__main__.Website object at 0x0000022B048DB750>\n"
     ]
    }
   ],
   "source": [
    "ed = Website(\"https://edwarddonner.com\")\n",
    "print(ed.title)\n",
    "print(ed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34a10e1f-6baf-4528-bfc8-83c1797f0c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our system prompt - you can experiment with this later, changing the last sentence to 'Respond in markdown in Spanish.\"\n",
    "\n",
    "system_prompt = \"You are an assistant that analyzes the contents of a website \\\n",
    "and provides a short summary, ignoring text that might be navigation related. \\\n",
    "Respond in markdown.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b11083e-fd32-42a7-945a-d17cd518fc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function that writes a User Prompt that asks for summaries of websites:\n",
    "\n",
    "def user_prompt_for(website):\n",
    "    user_prompt = f\"You are looking at a website titled {website.title}\"\n",
    "    user_prompt += \"\\nThe contents of this website is as follows; \\\n",
    "please provide a short summary of this website in markdown. \\\n",
    "If it includes news or announcements, then summarize these too.\\n\\n\"\n",
    "    user_prompt += website.text\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fec8e9b8-a5a4-4e45-a362-9b2015dcae2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To give you a preview -- calling OpenAI with system and user messages:\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "322a961a-ab84-4b2a-9c98-c035841ec868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how this function creates exactly the format above\n",
    "\n",
    "def messages_for(website):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_for(website)}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "93ea9f40-2e56-48ed-99f8-dfef99b63dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now: call the OpenAI API. You will get very familiar with this!\n",
    "\n",
    "def summarize(url):\n",
    "    website = Website(url)\n",
    "    response = ollama.chat(\n",
    "        model = MODEL,\n",
    "        messages = messages_for(website)\n",
    "    )\n",
    "    # return response.choices[0].message.content\n",
    "    return response.message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "71a5cea9-6b0a-4312-816e-5c150eeb5d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = summarize(\"https://edwarddonner.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6c5bfea6-749e-4a93-92db-f851301b10ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'### Home\\n\\nThis website serves as the homepage for Edward Donner, featuring an introduction to his work and interests.\\n\\n#### About\\n\\n* Brief bio of Edward Donner: a software engineer and entrepreneur who works on talent discovery and management through AI-powered LLMs.\\n* Links to follow him on LinkedIn, Twitter, Facebook, and newsletter subscription.\\n\\n### Posts\\n\\nThis section appears to be a collection of personal blog posts from Edward Donner. The topics include:\\n\\n* Brief updates on his work at Nebula.io, his co-founder and CTO\\n* Sharing his passions outside of work, such as DJing and electronic music production\\n* Reference to his involvement with Hacker News and nodding head in understanding complex concepts.\\n\\n### Announcements\\n\\nThere are no direct announcements or news updates mentioned on this website.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ea00f4b5-298a-4d8c-a074-104a3437d052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to display this nicely in the Jupyter output, using markdown\n",
    "\n",
    "def display_summary(url):\n",
    "    summary = summarize(url)\n",
    "    display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c6a58b7c-bef1-4d4d-9691-4abcc120a068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Home - Edward Donner\n",
       "\n",
       "The website features an arena where Large Language Models (LLMs) compete against each other, with the goal of diplomatic and devious strategies. It appears to be a platform for testing AI capabilities.\n",
       "\n",
       "#### About\n",
       "\n",
       "The author, Ed, is a co-founder and CTO of Nebula.io, a company applying AI to help people discover their potential and pursue their passion. They are also a well-known figure in the field of artificial intelligence.\n",
       "\n",
       "#### Posts\n",
       "\n",
       "*   Well, hi there.\n",
       "*   I’m Ed. I like writing code and experimenting with LLMs, and hopefully you’re here because you do too.\n",
       "*   I also enjoy DJing (but I’m badly out of practice), amateur electronic music production (\n",
       "*   very\n",
       "*   amateur) and losing myself in\n",
       "*   Hacker News\n",
       "*   , nodding my head sagely to things I only half understand."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://edwarddonner.com\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
